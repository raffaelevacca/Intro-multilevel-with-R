---
title: "Introduction to multilevel analysis in R with `lme4` and `tidyverse`"
author: 
  name: "Raffaele Vacca"
  email: "[raffaelevacca.com](https://www.raffaelevacca.com/)"
  affiliation: "University of Milan"
date: '`r Sys.Date()`'
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_file="./docs/index.html") })
bibliography: Multilevel_with_R.bib
link-citations: true
output: 
  html_document:
    toc: true
    number_sections: true
    toc_float: true
    theme: lumen
---

# Introduction

* This is an introduction to multilevel analysis with R for my seminars at the [UniMi NASP graduate school](https://www.nasp.eu/training/phd-programmes/esls.html) and [Behave Lab](https://behavelab.org/). 
* **Download these materials** [here](https://github.com/raffaelevacca/Intro-multilevel-with-R) (GitHub). 

**R packages and references**:

* I focus on (1) the [`lme4`](https://github.com/lme4/lme4) package for (Restricted) Maximum Likelihood Estimation of linear multilevel models [@bates_fitting_2015; @bates_lme4:_2012] and (2) integrating `lme4` with the [`tidyverse`](https://www.tidyverse.org/), a collection of R packages for data science (including `dplyr`, `ggplot2`, and `purrr`) with a common language and set of principles [@wickham_r_2017]. 
* I draw from the discussion of (linear) multilevel modeling by @fox_fitting_2018 and @fox_linear_2016. The example used in these materials is originally by @raudenbush_hierarchical_2002. Part of the code is also inspired to Wickham and Grolemund's [-@wickham_r_2017] treatment of statistical modeling with R (particularly in Ch. 20). 
* The data come from the [`MathAchieve`](https://rdrr.io/cran/nlme/man/MathAchieve.html) and [`MathAchSchool`](https://rdrr.io/cran/nlme/man/MathAchSchool.html) data frames in the [`nlme`](https://cran.r-project.org/web/packages/nlme/index.html) package. They derive from the "High School and Beyond" survey of 7185 students in 160 U.S. high schools, including 70 Catholic and 90 public schools [@fox_linear_2016; @raudenbush_hierarchical_2002]. See the links and references above for more documentation on these data.

**Further readings and resources**: 

* For statistical theory, details about estimation methods, and more in-depth overall treatment of the multilevel models presented in this introduction (in chronological order): @raudenbush_hierarchical_2002; @gelman_data_2006; @rasbash_lemma:_2008; @goldstein_multilevel_2010; @snijders_multilevel_2012; @simonoff_sage_2013; @fox_applied_2016 (Ch. 23-24).
* For more information about the R implementation of multilevel models, including different packages and estimation methods: @finch_multilevel_2014; @fox_fitting_2018;  [Ben Bolker](https://math.mcmaster.ca/~bolker/)'s [FAQ page](http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#introduction) about Generalized Linear Mixed Models.

## Setup instructions

To take this workshop you need to:

1. Download the last version of **R** [here](https://cran.r-project.org/mirrors.html) (select a location near you).
    * Follow instructions to install R on your computer.
2. Download **RStudio** (free version) [here](https://www.rstudio.com/products/rstudio/download/).
    * Follow instructions to install RStudio in your computer.
3. Install the **R packages** listed [below](#packages).
    * Open RStudio and go to `Top menu > Tools > Install packages...`.
    * Install each package in the list.
4. Bring your **laptop** to the workshop.
5. Download the **workshop project folder** [here](https://github.com/raffaelevacca/Intro-multilevel-with-R)
    * Click on the link > Click on the green `Clone` button > Download ZIP > Then unzip the folder in your computer.
    * I recommend doing this in class at the beginning of the workshop so as to download the most updated version of the folder.

Once in class, go to the workshop project folder (point 5 above) and double-click on the workshop R project file (`Multilevel_with_R.Rproj`) in it. This will open RStudio.

## Required R packages {#packages}

* General
    - [`broom`](https://broom.tidymodels.org/) to view model results as tidy tibbles.
    - [`magrittr`](https://magrittr.tidyverse.org/) for pipe and related operators.
    - [`tidyverse`](https://www.tidyverse.org/)
* To fit multilevel models and view their results
    - [`broom.mixed`](https://cran.r-project.org/web/packages/broom.mixed/vignettes/broom_mixed_intro.html)
    - [`car`](https://cran.r-project.org/web/packages/car/index.html) for tests of significance.
    - [`ggeffects`](https://strengejacke.github.io/ggeffects/) to calculate and visualize predicted values.
    - [`lme4`](https://github.com/lme4/lme4) for specifying and estimating multilevel models.
    - [`lmerTest`](https://www.jstatsoft.org/article/view/v082i13) for tests of significance on multilevel models.


```{r include=FALSE, cache=FALSE}
# Read script in
knitr::read_chunk("Multilevel_with_R.R")
```

# Explore and prepare the data

* Import and view the data in R.
* Obtain basic information about the multilevel structure of the data.
* Our dependent variable will be student's score from math assessment (`mathach`).
* Explanatory variables:
  * Student characteristics: score of socioeconomic status (SES), in deviation from school SES mean (`ses.dev`).
  * School characteristics: school's mean SES (`mean.ses`) and school sector (Public vs Catholic, `sector`).

```{r explore, message = FALSE}
```

* _How many students and schools are in the data?_
* _What's the average number of students per school?_
* _How many schools are Catholic, how many are Public?_

# Separate analyses by school: scatter plots

* Subset the data to a random sample of 20 Catholic schools and 20 Public schools.
* Obtain a scatter plot of student math score by student SES in each school, for the sampled Catholic and Public schools.

```{r scatterplots}
```

* _What do you notice about intercepts and slopes of the red regression lines? Are they constant across schools? _
* _What type of relationship between student's SES and math score do you see in schools? Does this relationship change between schools?_
* _Do you see any difference in the variability of regression lines among Catholic schools vis-a-vis Public schools?_

# Separate analyses by school: linear regressions

* Create a school-level nested data frame (`nested.df`) with each school's row including the data frame for that school's students.
* Use `nested.df` and `purrr::map` to estimate a separate linear regression model of math achievement on SES in each school.
* Put estimation results in new columns in the nested data frame.
* Visualize estimation results: 
  - Distribution of intercept and slope estimates by school sector (boxplots).
  - Distribution of intercept and slope estimates by school mean SES, by school sector (scatter plots).

```{r separate-reg, out.width= "100%", fig.height = 4}
```

* _In `nested.df$data`, what do the numbers of rows and columns indicate in each school's data frame?_
* _What differences do you see between the distribution of estimated *intercepts* in Public vs Catholic schools? What does this mean substantively?_
* _What differences do you see between the distribution of estimated *slopes* in Public vs Catholic schools? How do you interpret this substantively?_
* _What relationship emerges between school mean SES and school's estimated intercept? What about the same relationship for school's estimated slope? Are there differences between Public and Catholic schools in this respect?_

# Hierarchical Linear Model: variance components

* Estimate a two-level variance components model with students (level 1) nested in schools (level 2): `mod1`.
  - This is a random-intercept model with no predictor, which simply partitions `matchach` variation between variation at the student level (between students) and variation at the school level (between schools).
  - Here `mathach` is modeled as resulting from a school random effect (group level) plus a student random effect (individual or residual level): these are called $u_i$ and $e_i$, respectively, by @rasbash_lemma:_2008.
  - Like all models in this introduction, `mod1` is estimated via Restricted Maximum Likelihood (REML).
* Run a Likelihood Ratio Test (LRT) for the significance of school effects, comparing `mod1` with the same null linear model (no predictor) without taking into account student clustering in schools (i.e., a single-level model).
* See estimates for the variance components or random-effect parameters: the student-level variance and school-level variance -- called $\sigma^2_e$ and $\sigma^2_u$, respectively, by @rasbash_lemma:_2008.
* Use estimates for $\sigma^2_e$ and $\sigma^2_u$ to calculate the Variance Partition Coefficient (VPC):
  * This is the proportion of `mathach` variation that is attributable to the second level, that is, to between-school differences.
  * Note that in variance components models and random-intercept models (but not in random slope models) the VPC is the same as the Intraclass Correlation Coefficient (the correlation between `mathach` of two random students from the same school).

```{r var-comp}
```

* _How can we interpret the results from the variance components model?_
* _What proportion of `mathach` variation is explained by the school level? How does this compare with the correlation between math scores of two random students in the same school?_
* _According to the LRT, are school effects significant, that is, is the school level a significant source of variation in `mathach`?_

# Hierarchical Linear Model: random intercept

* Estimate `mod2`, a random intercept model with fixed slope for individual student SES.
* See estimates for the population-level fixed effects (`Intercept` and `ses.dev` slope) and for random-effect parameters.
* This model is the same as the previous variance components model, except that `mathach` is now explained in part by individual student SES (`ses.dev`), and its unexplained variation is partitioned between individual and school random effects.
  - The VPC increases slightly compared to `mod1`, indicating that a relatively higher proportion of the (unexplained) `mathach` variation is now explained by the school level: in other words, student SES absorbs part of the student-level variation which the previous `mod1` attributed to individual random effects ($e_i$).
* There is substantial debate on if and how to calculate (and report) p-values in multilevel models: 
  * See Ben Bolker's GLMM FAQ discussion of [this issue](http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#why-doesnt-lme4-display-denominator-degrees-of-freedomp-values-what-other-options-do-i-have), and of [tests of significance](http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#testing-hypotheses) for multilevel models in general.
  * We use [`lmerTest`](https://www.jstatsoft.org/article/view/v082i13)'s modification of the `summary` function to show p-values for single coefficient estimates based on t-tests with Satterthwaite's method.
  * But note that p-values would not by displayed if we applied the standard `summary` function to our estimated models.
  * Another option to test the significance of single coefficients is running the [`car::Anova`](https://www.rdocumentation.org/packages/car/versions/3.0-13/topics/Anova) function on the model object [see discussion by @fox_fitting_2018].

```{r rand-int}
```

* _How can we interpret the estimates for the fixed-effect parameters?_
* _How can we interpret the estimates for the variance components? _
* _Based on the VPC, what proportion of the `mathach` variation _not explained_ by `ses.dev` is attributable to the school level?_
  - _How does this differ from the interpretation of VPC in the variance components model `mod1`?_
  - _How can we interpret the increase in VPC compared to `mod1`?_

# Hierarchical Linear Model: random slope

* Estimate `mod3`, a random slope model with in which the effect of individual student SES on math score is allowed to vary between schools.
* View estimates for the different random-effect parameters in this model: variance of random intercept, variance of random slope, covariance between random intercept and random slope. 
  * These are called $\sigma^2_{u0}$, $\sigma^2_{u1}$ and $\sigma_{u01}$, respectively, by @rasbash_lemma:_2008.
  * Note that `lme4` model results show the _correlation_ $\rho_{u01}$ (not the covariance) between random intercept and random slope: to get the covariance just multiply the correlation times the two standard deviations ($\rho_{u01}*\sigma_{u0}*\sigma_{u1}$).

```{r rand-slo}
```

* _How many random effect parameters do we have now, compared to previous models? Why?_
* _How do we interpret the estimates for random intercept variance and random slope variance?_
* _How do we interpret the estimated correlation of random intercept and random slope?_

# Contextual variables and cross-level interactions

* We may hypothesize that school random intercept and random slope are in part explained by school-level ("contextual") variables: for example, `mean.ses` and `sector`. 
  * This idea can be represented as a random-slope model with `mean.ses` and `sector` as both main effects and interactions with `ses.dev` (see derivation in slides): `mod4`.
* Alternatively, we may estimate the same model but keeping the `ses.dev` slope fixed (i.e., a random-intercept model): `mod5`.
* We test whether `mod4` explains significantly more variation in the dependent variable compared to the simpler, more parsimonious `mod5` (Likelihood Ratio Test).
  - Based on LRT results, we don't have evidence to support the random slope (i.e., to reject the null hypothesis that the `ses.dev` slope is fixed across schools), so we choose `mod5` over `mod4`.
* From `mod5` we obtain predicted values of student `mathach` as a function of student `ses.dev`, given different contexts (i.e., different fixed values of school's `mean.ses` and `sector`). We then plot these results.

```{r contextual, out.width = "100%", fig.height = 3}
```

* _How many fixed effect parameters do we have now, compared to previous models? Why?_
* _What coefficient estimates are in `mod4` but _not_ in `mod5`? Why?_
* _How do we substantively interpret results of the LRT comparing `mod4` and `mod5`?_
* _How can we interpret the visualization of predicted values from `mod5`? What is the (fixed) effect of `ses.dev` on `mathach`? How does this change in Catholic vs Public schools? How does this change in schools whose student population has higher SES on average?_

# Examining school random effects and random intercepts

* Get the estimate for the fixed, population-level intercept in Public ($\beta_0$) and Catholic ($\beta_0+\beta_3$) schools (see slides for coefficient notation).
* Get estimates for the random effect of each school $j$ [called $u_j$ by @rasbash_lemma:_2008].
* Add the fixed intercept to each $u_j$ to obtain each school's estimated realization of the random intercept: $\beta_0+u_j$ for Public schools and $\beta_0+\beta_3+u_j$ for Catholic schools. 
  * This is the school's average math score at mean values of predictors (assuming predictors are centered).
* Identify "best" schools based on random intercept realization.
* Visualize the distribution of this random intercept and its association with school average SES (`mean.ses`) for Public and Catholic schools.

```{r rand-eff}
```

* _How do we interpret these last two plots?_

# References

<style>
    pre {
        border: 0;
    }
</style>

